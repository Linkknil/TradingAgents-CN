"""
è‡ªåŠ¨ä¸‹è½½åˆ†ææŠ¥å‘Šå·¥å…·
"""
import os
import json
import logging
from pathlib import Path
from typing import Dict, Any, Optional
from datetime import datetime

logger = logging.getLogger("app.utils.auto_download")


async def summarize_report_with_llm(report_content: str, stock_symbol: str, stock_name: str = None) -> Optional[str]:
    """
    ä½¿ç”¨å¤§æ¨¡å‹å¯¹æŠ¥å‘Šè¿›è¡Œç²¾ç¡®æ€»ç»“ï¼Œè¾“å‡ºä¸è¶…è¿‡500å­—çš„æ‘˜è¦
    
    Args:
        report_content: æŠ¥å‘Šå†…å®¹ï¼ˆMarkdownæ ¼å¼ï¼‰
        stock_symbol: è‚¡ç¥¨ä»£ç 
        stock_name: è‚¡ç¥¨åç§°ï¼ˆå¯é€‰ï¼‰
    
    Returns:
        æ€»ç»“å†…å®¹ï¼Œå¦‚æœå¤±è´¥åˆ™è¿”å›None
    """
    try:
        # è·å–é»˜è®¤LLMé…ç½®
        from app.services.simple_analysis_service import get_provider_and_url_by_model_sync
        from tradingagents.graph.trading_graph import create_llm_by_provider
        from app.services.config_service import ConfigService
        
        config_service = ConfigService()
        system_config = await config_service.get_system_config()
        
        if not system_config or not system_config.llm_configs:
            logger.warning("âš ï¸ æ— æ³•è·å–LLMé…ç½®ï¼Œè·³è¿‡æŠ¥å‘Šæ€»ç»“")
            return None
        
        # ä½¿ç”¨é»˜è®¤æ¨¡å‹æˆ–ç¬¬ä¸€ä¸ªå¯ç”¨çš„æ¨¡å‹
        default_model = system_config.default_llm
        if not default_model and system_config.llm_configs:
            default_model = system_config.llm_configs[0].model_name
        
        if not default_model:
            logger.warning("âš ï¸ æœªæ‰¾åˆ°å¯ç”¨çš„LLMæ¨¡å‹ï¼Œè·³è¿‡æŠ¥å‘Šæ€»ç»“")
            return None
        
        # è·å–æ¨¡å‹é…ç½®ä¿¡æ¯
        provider_info = get_provider_and_url_by_model_sync(default_model)
        if not provider_info.get("provider"):
            logger.warning(f"âš ï¸ æ— æ³•è·å–æ¨¡å‹ {default_model} çš„é…ç½®ï¼Œè·³è¿‡æŠ¥å‘Šæ€»ç»“")
            return None
        
        # æŸ¥æ‰¾æ¨¡å‹é…ç½®ä»¥è·å–temperatureå’Œmax_tokens
        model_config = None
        for llm_config in system_config.llm_configs:
            if llm_config.model_name == default_model:
                model_config = llm_config
                break
        
        temperature = model_config.temperature if model_config else 0.3
        max_tokens = min(model_config.max_tokens if model_config else 1000, 1000)  # é™åˆ¶æœ€å¤§tokenæ•°
        
        # åˆ›å»ºLLMå®ä¾‹
        llm = create_llm_by_provider(
            provider=provider_info["provider"],
            model=default_model,
            backend_url=provider_info.get("backend_url"),
            temperature=temperature,
            max_tokens=max_tokens,
            timeout=60,
            api_key=provider_info.get("api_key")
        )
        
        # æ„å»ºæ€»ç»“æç¤ºè¯
        stock_info = f"{stock_name}({stock_symbol})" if stock_name else stock_symbol
        
        # é™åˆ¶è¾“å…¥é•¿åº¦ï¼Œé¿å…è¶…å‡ºtokené™åˆ¶ï¼ˆä¿ç•™å‰8000å­—ç¬¦ï¼‰
        limited_content = report_content[:8000] if len(report_content) > 8000 else report_content
        
        prompt = f"""è¯·å¯¹ä»¥ä¸‹è‚¡ç¥¨åˆ†ææŠ¥å‘Šè¿›è¡Œç²¾ç¡®æ€»ç»“ï¼Œè¦æ±‚ï¼š
1. æ€»ç»“å†…å®¹ä¸è¶…è¿‡500å­—
2. é‡ç‚¹çªå‡ºæŠ•èµ„å†³ç­–ã€å…³é”®é£é™©ç‚¹å’Œæ ¸å¿ƒç»“è®º
3. è¯­è¨€ç®€æ´æ˜äº†ï¼Œé€»è¾‘æ¸…æ™°
4. ä¿ç•™æœ€é‡è¦çš„æ•°æ®å’Œåˆ†æè¦ç‚¹

è‚¡ç¥¨ï¼š{stock_info}
æŠ¥å‘Šå†…å®¹ï¼š
{limited_content}

è¯·æä¾›ä¸€ä»½ç²¾ç¡®çš„æ€»ç»“ï¼š"""
        
        logger.info(f"ğŸ¤– å¼€å§‹ä½¿ç”¨ {default_model} æ€»ç»“æŠ¥å‘Š...")
        
        # è°ƒç”¨LLMç”Ÿæˆæ€»ç»“
        response = llm.invoke(prompt)
        
        if response and hasattr(response, 'content') and response.content:
            summary = response.content.strip()
            
            # ç¡®ä¿æ€»ç»“ä¸è¶…è¿‡500å­—
            if len(summary) > 500:
                # å¦‚æœè¶…è¿‡500å­—ï¼Œæˆªå–å‰500å­—å¹¶æ·»åŠ çœç•¥å·
                summary = summary[:500] + "..."
                logger.warning(f"âš ï¸ æ€»ç»“è¶…è¿‡500å­—ï¼Œå·²æˆªå–å‰500å­—")
            
            logger.info(f"âœ… æŠ¥å‘Šæ€»ç»“å®Œæˆï¼Œé•¿åº¦: {len(summary)} å­—")
            return summary
        else:
            logger.warning("âš ï¸ LLMè¿”å›ç©ºå†…å®¹ï¼Œè·³è¿‡æ€»ç»“")
            return None
    
    except Exception as e:
        logger.error(f"âŒ ä½¿ç”¨LLMæ€»ç»“æŠ¥å‘Šå¤±è´¥: {e}", exc_info=True)
        return None


async def auto_download_report(
    report_id: str,
    stock_symbol: str,
    analysis_date: str,
    format: str = "markdown",
    save_path: Optional[str] = None,
    db=None,
    enable_summary: bool = False
) -> Optional[str]:
    """
    è‡ªåŠ¨ä¸‹è½½åˆ†ææŠ¥å‘Šåˆ°æœ¬åœ°æ–‡ä»¶ç³»ç»Ÿ
    
    Args:
        report_id: æŠ¥å‘ŠIDï¼ˆå¯ä»¥æ˜¯analysis_idæˆ–task_idï¼‰
        stock_symbol: è‚¡ç¥¨ä»£ç 
        analysis_date: åˆ†ææ—¥æœŸ
        format: ä¸‹è½½æ ¼å¼ (markdown, json, pdf, docx)
        save_path: ä¿å­˜è·¯å¾„ï¼ŒNoneè¡¨ç¤ºä½¿ç”¨é»˜è®¤è·¯å¾„
        db: MongoDBæ•°æ®åº“å®ä¾‹ï¼Œå¦‚æœä¸ºNoneåˆ™è‡ªåŠ¨è·å–
        enable_summary: æ˜¯å¦å¯ç”¨AIæŠ¥å‘Šæ€»ç»“ï¼ˆä»…Markdownæ ¼å¼æœ‰æ•ˆï¼‰
    
    Returns:
        ä¿å­˜çš„æ–‡ä»¶è·¯å¾„ï¼Œå¦‚æœå¤±è´¥åˆ™è¿”å›None
    """
    try:
        # å¦‚æœæ²¡æœ‰æä¾›dbï¼Œåˆ™è·å–
        if db is None:
            from app.core.database import get_mongo_db
            db = await get_mongo_db()
        
        # æ„å»ºæŸ¥è¯¢æ¡ä»¶ï¼ˆæ”¯æŒå¤šç§IDæ ¼å¼ï¼‰
        ors = [
            {"analysis_id": report_id},
            {"task_id": report_id},
        ]
        try:
            from bson import ObjectId
            ors.append({"_id": ObjectId(report_id)})
        except Exception:
            pass
        query = {"$or": ors}
        doc = await db.analysis_reports.find_one(query)
        
        if not doc:
            logger.warning(f"âš ï¸ æœªæ‰¾åˆ°æŠ¥å‘Š: {report_id}")
            return None
        
        # ç¡®å®šä¿å­˜è·¯å¾„
        if save_path:
            # ä½¿ç”¨ç”¨æˆ·æŒ‡å®šçš„è·¯å¾„
            if not os.path.isabs(save_path):
                # ç›¸å¯¹è·¯å¾„ï¼Œç›¸å¯¹äºé¡¹ç›®æ ¹ç›®å½•
                project_root = Path(__file__).parent.parent.parent
                save_dir = project_root / save_path
            else:
                save_dir = Path(save_path)
        else:
            # ä½¿ç”¨é»˜è®¤è·¯å¾„ï¼šé¡¹ç›®æ ¹ç›®å½•/downloads/reports/{è‚¡ç¥¨ä»£ç }/{åˆ†ææ—¥æœŸ}/
            project_root = Path(__file__).parent.parent.parent
            save_dir = project_root / "downloads" / "reports" / stock_symbol / analysis_date
        
        # åˆ›å»ºç›®å½•
        save_dir.mkdir(parents=True, exist_ok=True)
        
        # ç”Ÿæˆæ–‡ä»¶å
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        if format == "json":
            # JSONæ ¼å¼
            content = json.dumps(doc, ensure_ascii=False, indent=2, default=str)
            filename = f"{stock_symbol}_{analysis_date}_report_{timestamp}.json"
            file_path = save_dir / filename
            
            with open(file_path, 'w', encoding='utf-8') as f:
                f.write(content)
            
            logger.info(f"âœ… è‡ªåŠ¨ä¸‹è½½JSONæŠ¥å‘ŠæˆåŠŸ: {file_path}")
            return str(file_path)
        
        elif format == "markdown":
            # Markdownæ ¼å¼
            reports = doc.get("reports", {})
            content_parts = []
            
            # æ·»åŠ æ ‡é¢˜
            stock_name = doc.get("stock_name", stock_symbol)
            content_parts.append(f"# {stock_name}({stock_symbol}) åˆ†ææŠ¥å‘Š")
            content_parts.append(f"**åˆ†ææ—¥æœŸ**: {analysis_date}")
            content_parts.append(f"**åˆ†æå¸ˆ**: {', '.join(doc.get('analysts', []))}")
            content_parts.append(f"**ç ”ç©¶æ·±åº¦**: {doc.get('research_depth', 1)}")
            content_parts.append(f"**æ¨¡å‹ä¿¡æ¯**: {doc.get('model_info', 'Unknown')}")
            content_parts.append("")
            
            # æ·»åŠ æ‘˜è¦
            if doc.get("summary"):
                content_parts.append("## æ‰§è¡Œæ‘˜è¦")
                content_parts.append(doc["summary"])
                content_parts.append("")
            
            # æ·»åŠ å†³ç­–ä¿¡æ¯
            decision = doc.get("decision", {})
            if decision:
                content_parts.append("## æŠ•èµ„å†³ç­–")
                if isinstance(decision, dict):
                    content_parts.append(f"**è¡ŒåŠ¨**: {decision.get('action', 'N/A')}")
                    content_parts.append(f"**ç½®ä¿¡åº¦**: {decision.get('confidence', 0):.1%}")
                    content_parts.append(f"**é£é™©è¯„åˆ†**: {decision.get('risk_score', 0):.1%}")
                    content_parts.append(f"**ç›®æ ‡ä»·ä½**: {decision.get('target_price', 'N/A')}")
                    if decision.get('reasoning'):
                        content_parts.append(f"\n**åˆ†ææ¨ç†**:\n{decision['reasoning']}")
                else:
                    content_parts.append(str(decision))
                content_parts.append("")
            
            # æ·»åŠ å„æ¨¡å—å†…å®¹
            for module_name, module_content in reports.items():
                if isinstance(module_content, str) and module_content.strip():
                    # å°†æ¨¡å—åè½¬æ¢ä¸ºä¸­æ–‡æ ‡é¢˜
                    module_titles = {
                        'market_report': 'å¸‚åœºæŠ€æœ¯åˆ†ææŠ¥å‘Š',
                        'fundamentals_report': 'åŸºæœ¬é¢åˆ†ææŠ¥å‘Š',
                        'sentiment_report': 'å¸‚åœºæƒ…ç»ªåˆ†ææŠ¥å‘Š',
                        'news_report': 'æ–°é—»äº‹ä»¶åˆ†ææŠ¥å‘Š',
                        'investment_plan': 'æŠ•èµ„å†³ç­–æŠ¥å‘Š',
                        'trader_investment_plan': 'äº¤æ˜“è®¡åˆ’æŠ¥å‘Š',
                        'final_trade_decision': 'æœ€ç»ˆæŠ•èµ„å†³ç­–',
                        'research_team_decision': 'ç ”ç©¶å›¢é˜Ÿå†³ç­–æŠ¥å‘Š',
                        'risk_management_decision': 'é£é™©ç®¡ç†å›¢é˜Ÿå†³ç­–æŠ¥å‘Š'
                    }
                    title = module_titles.get(module_name, module_name.replace('_', ' ').title())
                    content_parts.append(f"## {title}")
                    content_parts.append(module_content)
                    content_parts.append("")
            
            # ç”Ÿæˆå®Œæ•´æŠ¥å‘Šå†…å®¹ï¼ˆç”¨äºæ€»ç»“ï¼‰
            full_content = "\n".join(content_parts)
            
            # åœ¨ä¸‹è½½å‰è°ƒç”¨å¤§æ¨¡å‹è¿›è¡Œæ€»ç»“ï¼ˆä»…å½“å¯ç”¨æ—¶ï¼‰
            llm_summary = None
            if enable_summary:
                logger.info("ğŸ¤– å¼€å§‹ç”ŸæˆæŠ¥å‘Šæ€»ç»“...")
                llm_summary = await summarize_report_with_llm(full_content, stock_symbol, stock_name)
            else:
                logger.debug("ğŸ“‹ æŠ¥å‘Šæ€»ç»“åŠŸèƒ½æœªå¯ç”¨ï¼Œè·³è¿‡æ€»ç»“")
            
            # å¦‚æœæœ‰æ€»ç»“ï¼Œå°†å…¶æ·»åŠ åˆ°æŠ¥å‘Šå¼€å¤´ï¼ˆåœ¨æ‰§è¡Œæ‘˜è¦ä¹‹å‰ï¼‰
            if llm_summary:
                # åœ¨æ ‡é¢˜åã€æ‰§è¡Œæ‘˜è¦å‰æ’å…¥AIæ€»ç»“
                summary_index = 0
                for i, part in enumerate(content_parts):
                    if part.startswith("## æ‰§è¡Œæ‘˜è¦"):
                        summary_index = i
                        break
                
                # å¦‚æœæ‰¾åˆ°äº†æ‰§è¡Œæ‘˜è¦ä½ç½®ï¼Œåœ¨å…¶å‰é¢æ’å…¥ï¼›å¦åˆ™åœ¨æ ‡é¢˜åæ’å…¥
                if summary_index > 0:
                    content_parts.insert(summary_index, "## AIç²¾ç¡®æ€»ç»“")
                    content_parts.insert(summary_index + 1, llm_summary)
                    content_parts.insert(summary_index + 2, "")
                else:
                    # å¦‚æœæ²¡æœ‰æ‰§è¡Œæ‘˜è¦ï¼Œåœ¨æ ‡é¢˜åæ’å…¥
                    content_parts.insert(6, "## AIç²¾ç¡®æ€»ç»“")
                    content_parts.insert(7, llm_summary)
                    content_parts.insert(8, "")
            
            content = "\n".join(content_parts)
            filename = f"{stock_symbol}_{analysis_date}_report_{timestamp}.md"
            file_path = save_dir / filename
            
            with open(file_path, 'w', encoding='utf-8') as f:
                f.write(content)
            
            logger.info(f"âœ… è‡ªåŠ¨ä¸‹è½½MarkdownæŠ¥å‘ŠæˆåŠŸ: {file_path}")
            return str(file_path)
        
        elif format in ["pdf", "docx"]:
            # PDFå’ŒDOCXæ ¼å¼éœ€è¦pandocæ”¯æŒ
            try:
                from app.utils.report_exporter import report_exporter
                
                if not report_exporter.pandoc_available:
                    logger.warning(f"âš ï¸ Pandocä¸å¯ç”¨ï¼Œæ— æ³•ç”Ÿæˆ{format}æ ¼å¼æŠ¥å‘Š")
                    # é™çº§ä¸ºmarkdownæ ¼å¼
                    return await auto_download_report(
                        report_id, stock_symbol, analysis_date, "markdown", save_path, db, enable_summary
                    )
                
                if format == "docx":
                    docx_content = report_exporter.generate_docx_report(doc)
                    filename = f"{stock_symbol}_{analysis_date}_report_{timestamp}.docx"
                    file_path = save_dir / filename
                    
                    with open(file_path, 'wb') as f:
                        f.write(docx_content)
                    
                    logger.info(f"âœ… è‡ªåŠ¨ä¸‹è½½DOCXæŠ¥å‘ŠæˆåŠŸ: {file_path}")
                    return str(file_path)
                
                elif format == "pdf":
                    pdf_content = report_exporter.generate_pdf_report(doc)
                    filename = f"{stock_symbol}_{analysis_date}_report_{timestamp}.pdf"
                    file_path = save_dir / filename
                    
                    with open(file_path, 'wb') as f:
                        f.write(pdf_content)
                    
                    logger.info(f"âœ… è‡ªåŠ¨ä¸‹è½½PDFæŠ¥å‘ŠæˆåŠŸ: {file_path}")
                    return str(file_path)
            
            except Exception as e:
                logger.error(f"âŒ ç”Ÿæˆ{format}æ ¼å¼æŠ¥å‘Šå¤±è´¥: {e}")
                # é™çº§ä¸ºmarkdownæ ¼å¼
                logger.info(f"ğŸ“ é™çº§ä¸ºMarkdownæ ¼å¼")
                return await auto_download_report(
                    report_id, stock_symbol, analysis_date, "markdown", save_path, db, enable_summary
                )
        
        else:
            logger.error(f"âŒ ä¸æ”¯æŒçš„ä¸‹è½½æ ¼å¼: {format}")
            return None
    
    except Exception as e:
        logger.error(f"âŒ è‡ªåŠ¨ä¸‹è½½æŠ¥å‘Šå¤±è´¥: {e}", exc_info=True)
        return None

